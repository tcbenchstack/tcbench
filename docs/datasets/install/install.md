## Supported datasets

TCBench integrates and *curates* the following traffic classification datasets

##### Table : Datasets properties
| Name | No. Classes | Links | Auto-download |
|:----:|:-----------:|:-----:|:-------------:|
|`ucdavis-icdm19`|5|[:fontawesome-regular-file-pdf:](https://arxiv.org/pdf/1812.09761.pdf)[:material-package-down:](https://drive.google.com/drive/folders/1Pvev0hJ82usPh6dWDlz7Lv8L6h3JpWhE)[:material-github:](https://github.com/shrezaei/Semi-supervised-Learning-QUIC-)|:octicons-x-12:|
|`mirage19`|20|[:fontawesome-regular-file-pdf:](http://wpage.unina.it/antonio.montieri/pubs/MIRAGE_ICCCS_2019.pdf)[:material-package-down:](https://traffic.comics.unina.it/mirage/MIRAGE/MIRAGE-2019_traffic_dataset_downloadable_v2.tar.gz)[:material-web:](https://traffic.comics.unina.it/mirage/mirage-2019.html)|:heavy_check_mark:|
|`mirage22`|9|[:fontawesome-regular-file-pdf:](http://wpage.unina.it/antonio.montieri/pubs/_C__IEEE_CAMAD_2021___Traffic_Classification_Covid_app.pdf)[:material-package-down:](https://traffic.comics.unina.it/mirage/MIRAGE/MIRAGE-COVID-CCMA-2022.zip)[:material-web:](https://traffic.comics.unina.it/mirage/mirage-covid-ccma-2022.html)|:heavy_check_mark:|
|`utmobilenet21`|17|[:fontawesome-regular-file-pdf:](https://ieeexplore.ieee.org/abstract/document/9490678/)[:material-package-down:](https://github.com/YuqiangHeng/UTMobileNetTraffic2021)[:material-github:](https://github.com/YuqiangHeng/UTMobileNetTraffic2021)|:octicons-x-12:|

Unfortunately, there is no single format used when preparing datasets for public release.

* Datasets come as __either CSV or JSON files collections__ with either
per-packet or per-flow records. 

* __Files can be organized in subfolders__, namely __partitions__,
named to reflect the related measurement campaign
(see `ucdavis-icdm19`, `utmobilenet21`).

* __File names can carry semantic__ and/or the classification 
require preprocessing to be obtained by separating
it from background (see `mirage19` and `mirage22`).

* Datasets typically __do not have native splits__
(i.e., train/validation/test splits) nor are ready to use
for app modeling (e.g., ICMP packets, short flows, etc., are not filtered).

## Datasets curation at-glance

:material-target:
==*We target per-flow classification where each flow is
associated to packet time series input.*==
:material-target:

To do so, we take an opinionated view on how
datasets should be formatted and handled.

Specifically, when installing a dataset, the dataset raw
data goes through the following steps:

1. __Download and unpack__: `tcbench` enables you
to directly fetch the raw data from the Internet or install it
from a folder where data was pre-downloaded, and
unpack it into a predefined destination folder which, 
for simplicity, corresponds to a
subfolder of the python environment where 
[`tcbench` is installed](/modeling_framework/install).
This folder is mantained and can accessed for futher
ad-hoc processing outside the functionalities of `tcbench`.

2. __Preprocess__: Once unpacked, the dataset
raw data is converted into __monolithic packet files__.
Such files are left *untouched*, i.e., they simply
serve as a re-organization of the original data
(with a per-flow view where needed) with an
homogeneous format across datasets.

3. __Filter and split__: The monolithic parquet files
are first filtered (e.g., removing very short
flows or flow related to invalid IP addresses) and
then used to train/validation/test splits.
Both steps are necessary to enable traffic modeling
and replicability; yet they reflect our opinionated view
on how to handle dataset for traffic classification.

## Datasets meta-data

As part of the curation process, 
`tcbench` enables you to show meta-data
related to the datasets.

For instance, the refences collected
in the [summary table](#table-datasets-properties) reported
at the top of this page
can be visualized issuing

```
tcbench datasets info
```

!!! info "Output"
	```
	Datasets
	â”œâ”€â”€ ucdavis-icdm19
	â”‚   â””â”€â”€  ğŸš© classes:       5
	â”‚        ğŸ”— paper_url:     https://arxiv.org/pdf/1812.09761.pdf
	â”‚        ğŸ”— website:       https://github.com/shrezaei/Semi-supervised-Learning-QUIC-
	â”‚        ğŸ”— data:          https://drive.google.com/drive/folders/1Pvev0hJ82usPh6dWDlz7Lv8L6h3JpWhE
	â”‚        ğŸ“ installed:     None
	â”‚        ğŸ“ preprocessed:  None
	â”‚        ğŸ“ data splits:   None
	â”œâ”€â”€ mirage19
	â”‚   â””â”€â”€  ğŸš© classes:       20
	â”‚        ğŸ”— paper_url:     http://wpage.unina.it/antonio.montieri/pubs/MIRAGE_ICCCS_2019.pdf
	â”‚        ğŸ”— website:       https://traffic.comics.unina.it/mirage/mirage-2019.html
	â”‚        ğŸ”— data:          https://traffic.comics.unina.it/mirage/MIRAGE/MIRAGE-2019_traffic_dataset_downloadable_v2.tar.gz
	â”‚        ğŸ“ installed:     None
	â”‚        ğŸ“ preprocessed:  None
	â”‚        ğŸ“ data splits:   None
	â”œâ”€â”€ mirage22
	â”‚   â””â”€â”€  ğŸš© classes:       9
	â”‚        ğŸ”— paper_url:     http://wpage.unina.it/antonio.montieri/pubs/_C__IEEE_CAMAD_2021___Traffic_Classification_Covid_app.pdf
	â”‚        ğŸ”— website:       https://traffic.comics.unina.it/mirage/mirage-covid-ccma-2022.html
	â”‚        ğŸ”— data:          https://traffic.comics.unina.it/mirage/MIRAGE/MIRAGE-COVID-CCMA-2022.zip
	â”‚        ğŸ“ installed:     None
	â”‚        ğŸ“ preprocessed:  None
	â”‚        ğŸ“ data splits:   None
	â””â”€â”€ utmobilenet21
		â””â”€â”€  ğŸš© classes:       17
			 ğŸ”— paper_url:     https://ieeexplore.ieee.org/abstract/document/9490678/
			 ğŸ”— website:       https://github.com/YuqiangHeng/UTMobileNetTraffic2021
			 ğŸ”— data:          https://utexas.app.box.com/s/okrimcsz1mn9ec4j667kbb00d9gt16ii
			 ğŸ“ installed:     None
			 ğŸ“ preprocessed:  None
			 ğŸ“ data splits:   None
	```


Beside showing the a set of static properties (e.g., URL links), 
the 3 properties `installed`, `preprocessed` nd `data_splits` 
reports the absolute path where the related data is stored.
The example refers to the initial setup where no dataset is yet
installed.

However, when [unpacking artifacts with the 
provided scripts](/artifacts/#unpack-artifacts), 
the curated datasets are automatically installed

```
tcbench datasets info
```

!!! info "Output"
	```
	Datasets
	â”œâ”€â”€ ucdavis-icdm19
	â”‚   â””â”€â”€  ğŸš© classes:       5
	â”‚        ğŸ”— paper_url:     https://arxiv.org/pdf/1812.09761.pdf
	â”‚        ğŸ”— website:       https://github.com/shrezaei/Semi-supervised-Learning-QUIC-
	â”‚        ğŸ”— data:          https://drive.google.com/drive/folders/1Pvev0hJ82usPh6dWDlz7Lv8L6h3JpWhE
	â”‚        ğŸ“ installed:     None
	â”‚        ğŸ“ preprocessed:  /home/johndoe/.conda/envs/tcbench-johndoe/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed
	â”‚        ğŸ“ data splits:   /home/johndoe/.conda/envs/tcbench-johndoe/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/imc23
	â”œâ”€â”€ mirage19
	â”‚   â””â”€â”€  ğŸš© classes:       20
	â”‚        ğŸ”— paper_url:     http://wpage.unina.it/antonio.montieri/pubs/MIRAGE_ICCCS_2019.pdf
	â”‚        ğŸ”— website:       https://traffic.comics.unina.it/mirage/mirage-2019.html
	â”‚        ğŸ”— data:          https://traffic.comics.unina.it/mirage/MIRAGE/MIRAGE-2019_traffic_dataset_downloadable_v2.tar.gz
	â”‚        ğŸ“ installed:     None
	â”‚        ğŸ“ preprocessed:  /home/johndoe/.conda/envs/tcbench-johndoe/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/mirage19/preprocessed
	â”‚        ğŸ“ data splits:   /home/johndoe/.conda/envs/tcbench-johndoe/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/mirage19/preprocessed/imc23
	â”œâ”€â”€ mirage22
	â”‚   â””â”€â”€  ğŸš© classes:       9
	â”‚        ğŸ”— paper_url:     http://wpage.unina.it/antonio.montieri/pubs/_C__IEEE_CAMAD_2021___Traffic_Classification_Covid_app.pdf
	â”‚        ğŸ”— website:       https://traffic.comics.unina.it/mirage/mirage-covid-ccma-2022.html
	â”‚        ğŸ”— data:          https://traffic.comics.unina.it/mirage/MIRAGE/MIRAGE-COVID-CCMA-2022.zip
	â”‚        ğŸ“ installed:     None
	â”‚        ğŸ“ preprocessed:  /home/johndoe/.conda/envs/tcbench-johndoe/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/mirage22/preprocessed
	â”‚        ğŸ“ data splits:   /home/johndoe/.conda/envs/tcbench-johndoe/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/mirage22/preprocessed/imc23
	â””â”€â”€ utmobilenet21
		â””â”€â”€  ğŸš© classes:       17
			 ğŸ”— paper_url:     https://ieeexplore.ieee.org/abstract/document/9490678/
			 ğŸ”— website:       https://github.com/YuqiangHeng/UTMobileNetTraffic2021
			 ğŸ”— data:          https://utexas.app.box.com/s/okrimcsz1mn9ec4j667kbb00d9gt16ii
			 ğŸ“ installed:     None
			 ğŸ“ preprocessed:  /home/johndoe/.conda/envs/tcbench-johndoe/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/utmobilenet21/preprocessed
			 ğŸ“ data splits:   /home/johndoe/.conda/envs/tcbench-johndoe/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/utmobilenet21/preprocessed/imc23
	```
	
	Notice that
	* __installed__ is `None` because this refers to the
		original raw data of the datasets (which is not
		provided with the curated artifacts).

	* __preprocessed__ and __data splits__ are two specific types
		of curation of the datasets.

	In fact, the artifacts unpacking uses a [dataset import](/datasets/import) process.


When installing a dataset, `tcbench` also
shows two types of reports as formatted tables.

* __Samples count__: This tables collect
the number of samples (i.e., flows)
available.

* __Stats__: The curation process
can filter out flows (e.g., based
on a minum number of packets
or remove classes without a minimum
number of flows). As such, when 
installing, `tcbench` is showing
general stats (mean, std, percentiles)
about number of packets
for each flow across classes.

Please check out the [datasets meta-data](/datasets/metadata) page for more details.


## `ucdavis-icdm19`

This dataset cannot be downloaded directly
(as it is stored on Google Drive). So,
it needs to be manually downloaded.

More specifically, the dataset is composed
of 3 zip files that need to be kept in
a single folder.

For instance
```
downloads/
â”œâ”€â”€ pretraining.zip
â”œâ”€â”€ Retraining(human-triggered).zip
â””â”€â”€ Retraining(script-triggered).zip
```

#### Original structure

The 3 files correspond to 3 *partitions*
with different scopes: `pretraining` is 
meant for training while the other two
for testing.

When all zips are unpacked, the folder structure becomes
```
downloads/
â”œâ”€â”€ pretraining
â”‚Â Â  â”œâ”€â”€ Google Doc
â”‚Â Â  â”œâ”€â”€ Google Drive
â”‚Â Â  â”œâ”€â”€ Google Music
â”‚Â Â  â”œâ”€â”€ Google Search
â”‚Â Â  â””â”€â”€ Youtube
â”œâ”€â”€ Retraining(human-triggered)
â”‚Â Â  â”œâ”€â”€ Google Doc
â”‚Â Â  â”œâ”€â”€ Google Drive
â”‚Â Â  â”œâ”€â”€ Google Music
â”‚Â Â  â”œâ”€â”€ Google Search
â”‚Â Â  â””â”€â”€ Youtube
â””â”€â”€ Retraining(script-triggered)
    â”œâ”€â”€ Google Doc
    â”œâ”€â”€ Google Drive
    â”œâ”€â”€ Google Music
    â”œâ”€â”€ Google Search
    â””â”€â”€ Youtube
```

Inside each nested folder there is a collection of CSV files.
Each file corresponds to a different flow, 
where each row represents individual packet information.

#### Curation

* __No filtering__ is applied to the original data.

* The only processing applied is to "transpose" 
the data with respect to the original representation.
Specifically, original CSV are per-packet while we
create pandas DataFrames where one row 
represents one flow and we gather
all packets of the flow into numpy arrays.

* During the conversion the original folder
structure is preserved via extra columns
(`partition` and `flow_id`).

#### Splits

This dataset was used in [:material-file-document-outline:`imc22-paper`](/index.md), hence we follow the splits described in the paper

* From `pretraining` we generate 5 random splits, each with 100 samples per class.
* The other two partitions are left as is and are used for testing.

Both training and testing splits are "materialized", i.e.,
differently from `mirage19`, `mirage22`, and `utmobilenet21`,
the splits are NOT collection or row indexes but
rather already filtered views of the monolithic 
parquet files.

Hence, all splits have the same columns.

| Field | Description |
|:------|:------------|
|`row_id`| A unique row id|
|`app`| The label of the flow, encoded as pandas `category`|
|`flow_id`| The original filename|
|`partition`| The partition related to the flow|
|`num_pkts`| Number of packets in the flow|
|`duration`| The duration of the flow|
|`bytes`| The number of bytes of the flow|
|`unixtime`| Numpy array with the absolute time of each packet|
|`timetofirst`| Numpy array with the delta between a packet the first packet of the flow|
|`pkts_size`| Numpy array for the packet size time series|
|`pkts_dir`| Numpy array for the packet direction time series|
|`pkts_iat`| Numpy array for the packet inter-arrival time series|

#### Install

To install the dataset run (assuming data was pre-downloaded under `/downloads`)

```
tcbench datasets install \
	--name ucdavis-icdm19 \
	--input-folder ./downloads/
```


!!! info "Output"
	```
    â•­â”€â”€â”€â”€â”€â”€â•®
    â”‚unpackâ”‚
    â•°â”€â”€â”€â”€â”€â”€â•¯
    opening: downloads/pretraining.zip
    opening: downloads/Retraining(human-triggered).zip
    opening: downloads/Retraining(script-triggered).zip

    â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
    â”‚preprocessâ”‚
    â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
    found 6672 CSV files to load
    Converting CSVs... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:00
    concatenating files
    saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/ucdavis-icdm19.parquet
    samples count : unfiltered
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
    â”ƒ partition                   â”ƒ app           â”ƒ samples â”ƒ
    â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
    â”‚ pretraining                 â”‚ google-doc    â”‚    1221 â”‚
    â”‚                             â”‚ google-drive  â”‚    1634 â”‚
    â”‚                             â”‚ google-music  â”‚     592 â”‚
    â”‚                             â”‚ google-search â”‚    1915 â”‚
    â”‚                             â”‚ youtube       â”‚    1077 â”‚
    â”‚                             â”‚ __total__     â”‚    6439 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ retraining-human-triggered  â”‚ google-doc    â”‚      15 â”‚
    â”‚                             â”‚ google-drive  â”‚      18 â”‚
    â”‚                             â”‚ google-music  â”‚      15 â”‚
    â”‚                             â”‚ google-search â”‚      15 â”‚
    â”‚                             â”‚ youtube       â”‚      20 â”‚
    â”‚                             â”‚ __total__     â”‚      83 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ retraining-script-triggered â”‚ google-doc    â”‚      30 â”‚
    â”‚                             â”‚ google-drive  â”‚      30 â”‚
    â”‚                             â”‚ google-music  â”‚      30 â”‚
    â”‚                             â”‚ google-search â”‚      30 â”‚
    â”‚                             â”‚ youtube       â”‚      30 â”‚
    â”‚                             â”‚ __total__     â”‚     150 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
    â”‚generate splitsâ”‚
    â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
    saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/imc23/train_split_0.parquet
    saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/imc23/train_split_1.parquet
    saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/imc23/train_split_2.parquet
    saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/imc23/train_split_3.parquet
    saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/imc23/train_split_4.parquet
    samples count : train_split = 0 to 4
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
    â”ƒ app           â”ƒ samples â”ƒ
    â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
    â”‚ google-doc    â”‚     100 â”‚
    â”‚ google-drive  â”‚     100 â”‚
    â”‚ google-music  â”‚     100 â”‚
    â”‚ google-search â”‚     100 â”‚
    â”‚ youtube       â”‚     100 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ __total__     â”‚     500 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/imc23/test_split_human.parquet
    samples count : test_split_human
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
    â”ƒ app           â”ƒ samples â”ƒ
    â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
    â”‚ youtube       â”‚      20 â”‚
    â”‚ google-drive  â”‚      18 â”‚
    â”‚ google-doc    â”‚      15 â”‚
    â”‚ google-music  â”‚      15 â”‚
    â”‚ google-search â”‚      15 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ __total__     â”‚      83 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/imc23/test_split_script.parquet
    samples count : test_split_script
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
    â”ƒ app           â”ƒ samples â”ƒ
    â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
    â”‚ google-doc    â”‚      30 â”‚
    â”‚ google-drive  â”‚      30 â”‚
    â”‚ google-music  â”‚      30 â”‚
    â”‚ google-search â”‚      30 â”‚
    â”‚ youtube       â”‚      30 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ __total__     â”‚     150 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	```

!!! note "Focusing on the reports..."

	Notice the following:

	* There is a monolithic parquet file containing the original partitions. For readability, the samples count report is groupped by partition
	* There are 5 train splits (with 100 samples per class)
	* There are 2 test splits (i.e., `human` and `script`) matching the related partitions from the raw dataset.




## `mirage19`

The dataset is a collection of JSON files gathering per-flow
data from 20 Android apps.

!!! Warning "...but why not 40 apps?"
    Despite the [`mirage19` website](https://traffic.comics.unina.it/mirage/mirage-2019.html) and the [related paper](http://wpage.unina.it/antonio.montieri/pubs/MIRAGE_ICCCS_2019.pdf) mention
	the availability of 40 applications, the public version
    has only 20. With separate communication with the authors
    of the dataset, we understood that the remaining 20
    are available only upon request (altough not explicitly
    specified). As result, we considered only the 20 publicly
    available.

The dataset can be downloaded directly by `tcbench`
or can be pre-downloaded and placed into a folder.

For instance
```
downloads/
â””â”€â”€ MIRAGE-2019_traffic_dataset_downloadable_v2.tar.gz 
```

#### Original structure

Once unpacked the dataset has
the following structure
```
downloads/
â””â”€ MIRAGE-2019_traffic_dataset_downloadable
Â Â  â”œâ”€â”€ Mi5_38_a4_ed_18_cc_bf
Â Â  â””â”€â”€ Nexus7_bc_ee_7b_a4_09_47
```

The subfolders contain collections of JSON files,
each representing a different experiment.
The application is encoded both in the filenames
as well as extra metadata in the JSON structure
(`flow` :material-arrow-right: `metadata` :material-arrow-right: `bf` :material-arrow-right: `label`).
    
Each JSON file is already per-flow, but they have
a fairly complicated nested structure.
For example, aggregate flow metrics are
hierarchially separated from packet time series,
which are further separated from other metadata.

#### Curation

1. Combine all JSON into a monolithic parquet file.

2. __Flatten the JSON nested structure__. 
	For instance, the nested input dictionary
    `{"layer1":{"col1":1, "col2":2}}` 
	would be flattened into a table
	with columns "layer1_col1" and "layer1_col2" 
	with the respective values "1" and "2".

3. Add a __`"background"` class__. More specifically,
    each JSON file details the Android 
	app name in the file name. But the traffic in an experiment
    can be related to a different app/service running in parallel.
	However, the dataset offers the column
    `flow_metadata_bf_label` which contains the
	Android app name that `netstat` linked to each
    network socket during an experiment.
	This implies that, by knowing the expected app
	of an experiment, one can define as "background" 
	:material-arrow-right: `flow_metadata_bf_label` != 
    expected Android app name.

4. The dataset contains raw packet bytes across multiple packets
    of a flow. We process these series to search for 
	__ASCII strings__.
    This can be usefull for extract (in a lazy way) TLS
    handshake information (e.g., SNI or certificate info).

The final parquet files has 127 columns, and most of
them comes from the original dataset itself.
They are not documented but fairly easy to understand
based on the name. Thus, __we prune some
columns in the final filtered files__.

The most important ones are

|Field|Description|
|:----|:----------|
|`packet_data_packet_dir`|The time series of the packet direction|
|`packet_data_l4_payload_bytes`|The time series of the packet size|
|`packet_data_iat`|The time series of the packet inter-arrival time|
|`flow_metadata_bf_label`|The label gathered via netstat|
|`strings`|The ASCII string recovered from the payload analysis|
|`android_name`|The app used for an experiment|
|`app`|The final label encoded as a pandas `category`|
|`row_id`|A unique row identifier|

Please refer to the [datasets schema](/datasets/metadata/#schemas) page for more details.

#### Splits

Once preprocessed, the monolithic dataset is further processed to:

* Remove ACK packets from time series.
* Remove flows with < 10 samples.
* Remove apps with < 100 samples.

From the remaining traffic we define 5 train/val/test splits with the following logic

1. Shuffle the rows.
2. Perform a 90/10 split where the 10-part is used for testing.
3. From the 90-part, do a second 90/10 to define train and validation.

The splits are NOT materialized, i.e., 
splits are a collection of row indexes
that needs to be applied on the filtered monolithic
parquet in order to obtain the data for modeling

The structure of the splits table is as follows

|Field|Description|
|:----|:----------|
|`train_indexes`|A numpy array with the `row_id` related to the train split|
|`val_indexes`| ... validation split|
|`test_indexes`| ... test split|
|`split_index`| The index of the split (0..4)|


#### Install

To install the dataset run

```
tcbench datasets install --name mirage19
```

!!! info "Output"
	```
	â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
	â”‚download & unpackâ”‚
	â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
	Downloading... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.5 GB / 1.5 GB eta 0:00:00
	opening: /tmp/tmpxcdzy8tw/MIRAGE-2019_traffic_dataset_downloadable_v2.tar.gz

	â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
	â”‚preprocessâ”‚
	â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
	found 1642 JSON files to load
	Converting JSONs... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1642/1642 0:00:11
	merging files...
	saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/mirage19/preprocessed/mirage19.parquet

	â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
	â”‚filter & generate splitsâ”‚
	â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
	loading: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/mirage19/preprocessed/mirage19.parquet
	samples count : unfiltered
	â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
	â”ƒ app                         â”ƒ samples â”ƒ
	â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
	â”‚ com.waze                    â”‚   11737 â”‚
	â”‚ de.motain.iliga             â”‚   10810 â”‚
	â”‚ com.accuweather.android     â”‚   10631 â”‚
	â”‚ com.duolingo                â”‚    8319 â”‚
	â”‚ it.subito                   â”‚    8167 â”‚
	â”‚ com.contextlogic.wish       â”‚    6507 â”‚
	â”‚ com.spotify.music           â”‚    6431 â”‚
	â”‚ com.joelapenna.foursquared  â”‚    6399 â”‚
	â”‚ com.google.android.youtube  â”‚    6346 â”‚
	â”‚ com.iconology.comics        â”‚    5516 â”‚
	â”‚ com.facebook.katana         â”‚    5368 â”‚
	â”‚ com.dropbox.android         â”‚    4815 â”‚
	â”‚ com.twitter.android         â”‚    4734 â”‚
	â”‚ background                  â”‚    4439 â”‚
	â”‚ com.pinterest               â”‚    4078 â”‚
	â”‚ com.facebook.orca           â”‚    4018 â”‚
	â”‚ com.tripadvisor.tripadvisor â”‚    3572 â”‚
	â”‚ air.com.hypah.io.slither    â”‚    3088 â”‚
	â”‚ com.viber.voip              â”‚    2740 â”‚
	â”‚ com.trello                  â”‚    2306 â”‚
	â”‚ com.groupon                 â”‚    1986 â”‚
	â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
	â”‚ __total__                   â”‚  122007 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	stats : number packets per-flow (unfiltered)
	â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”“
	â”ƒ stat  â”ƒ    value â”ƒ
	â”¡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”©
	â”‚ count â”‚ 122007.0 â”‚
	â”‚ mean  â”‚    23.11 â”‚
	â”‚ std   â”‚     9.73 â”‚
	â”‚ min   â”‚      1.0 â”‚
	â”‚ 25%   â”‚     17.0 â”‚
	â”‚ 50%   â”‚     26.0 â”‚
	â”‚ 75%   â”‚     32.0 â”‚
	â”‚ max   â”‚     32.0 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

	filtering min_pkts=10...
	saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/mirage19/preprocessed/imc23/mirage19_filtered_minpkts10.parquet
	samples count : filtered (min_pkts=10)
	â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
	â”ƒ app                         â”ƒ samples â”ƒ
	â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
	â”‚ de.motain.iliga             â”‚    7505 â”‚
	â”‚ com.waze                    â”‚    7214 â”‚
	â”‚ com.duolingo                â”‚    4583 â”‚
	â”‚ it.subito                   â”‚    4299 â”‚
	â”‚ com.contextlogic.wish       â”‚    3927 â”‚
	â”‚ com.accuweather.android     â”‚    3737 â”‚
	â”‚ com.joelapenna.foursquared  â”‚    3627 â”‚
	â”‚ com.spotify.music           â”‚    3300 â”‚
	â”‚ com.dropbox.android         â”‚    3189 â”‚
	â”‚ com.facebook.katana         â”‚    2878 â”‚
	â”‚ com.iconology.comics        â”‚    2812 â”‚
	â”‚ com.twitter.android         â”‚    2805 â”‚
	â”‚ com.google.android.youtube  â”‚    2728 â”‚
	â”‚ com.pinterest               â”‚    2450 â”‚
	â”‚ com.tripadvisor.tripadvisor â”‚    2052 â”‚
	â”‚ com.facebook.orca           â”‚    1783 â”‚
	â”‚ com.viber.voip              â”‚    1618 â”‚
	â”‚ com.trello                  â”‚    1478 â”‚
	â”‚ com.groupon                 â”‚    1174 â”‚
	â”‚ air.com.hypah.io.slither    â”‚    1013 â”‚
	â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
	â”‚ __total__                   â”‚   64172 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	stats : number packets per-flow (min_pkts=10)
	â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
	â”ƒ stat  â”ƒ   value â”ƒ
	â”¡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
	â”‚ count â”‚ 64172.0 â”‚
	â”‚ mean  â”‚   17.01 â”‚
	â”‚ std   â”‚    4.43 â”‚
	â”‚ min   â”‚    11.0 â”‚
	â”‚ 25%   â”‚    14.0 â”‚
	â”‚ 50%   â”‚    17.0 â”‚
	â”‚ 75%   â”‚    19.0 â”‚
	â”‚ max   â”‚    32.0 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/mirage19/preprocessed/imc23/mirage19_filtered_minpkts10_splits.parquet
	â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
	â”ƒ app                         â”ƒ train_samples â”ƒ val_samples â”ƒ test_samples â”ƒ all_samples â”ƒ
	â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
	â”‚ de.motain.iliga             â”‚          6079 â”‚         675 â”‚          751 â”‚        7505 â”‚
	â”‚ com.waze                    â”‚          5844 â”‚         649 â”‚          721 â”‚        7214 â”‚
	â”‚ com.duolingo                â”‚          3712 â”‚         413 â”‚          458 â”‚        4583 â”‚
	â”‚ it.subito                   â”‚          3482 â”‚         387 â”‚          430 â”‚        4299 â”‚
	â”‚ com.contextlogic.wish       â”‚          3181 â”‚         353 â”‚          393 â”‚        3927 â”‚
	â”‚ com.accuweather.android     â”‚          3027 â”‚         336 â”‚          374 â”‚        3737 â”‚
	â”‚ com.joelapenna.foursquared  â”‚          2938 â”‚         326 â”‚          363 â”‚        3627 â”‚
	â”‚ com.spotify.music           â”‚          2673 â”‚         297 â”‚          330 â”‚        3300 â”‚
	â”‚ com.dropbox.android         â”‚          2583 â”‚         287 â”‚          319 â”‚        3189 â”‚
	â”‚ com.facebook.katana         â”‚          2331 â”‚         259 â”‚          288 â”‚        2878 â”‚
	â”‚ com.iconology.comics        â”‚          2278 â”‚         253 â”‚          281 â”‚        2812 â”‚
	â”‚ com.twitter.android         â”‚          2272 â”‚         252 â”‚          281 â”‚        2805 â”‚
	â”‚ com.google.android.youtube  â”‚          2209 â”‚         246 â”‚          273 â”‚        2728 â”‚
	â”‚ com.pinterest               â”‚          1984 â”‚         221 â”‚          245 â”‚        2450 â”‚
	â”‚ com.tripadvisor.tripadvisor â”‚          1662 â”‚         185 â”‚          205 â”‚        2052 â”‚
	â”‚ com.facebook.orca           â”‚          1444 â”‚         161 â”‚          178 â”‚        1783 â”‚
	â”‚ com.viber.voip              â”‚          1310 â”‚         146 â”‚          162 â”‚        1618 â”‚
	â”‚ com.trello                  â”‚          1197 â”‚         133 â”‚          148 â”‚        1478 â”‚
	â”‚ com.groupon                 â”‚           951 â”‚         106 â”‚          117 â”‚        1174 â”‚
	â”‚ air.com.hypah.io.slither    â”‚           821 â”‚          91 â”‚          101 â”‚        1013 â”‚
	â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
	â”‚ __total__                   â”‚         51978 â”‚        5776 â”‚         6418 â”‚       64172 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	```

!!! note "Focusing on the reports..."

	Notice the following:

	* The unfiltered dataset has many flows but observe (see packets stats) that those are mostly short.
	* The splits are formed so to have roughly 100 samples for validation/test.

## Install `mirage22`

The dataset is from the same authors of `mirage19` so 
the two datasets have many commonalities.

The major difference is the dataset aim: It focuses
on video meeting Android apps with experiments
annotated with respect to different interactions
the the apps (voice, chat, etc.)


#### Original structure

The dataset can be downloaded automatically 
(or can be pre-downloaded into a folder).

For instance
```
downloads/
â””â”€â”€ MIRAGE-COVID-CCMA-2022.zip
```

Once unpacked it has the following structure
```
downloads/
â””â”€â”€ MIRAGE-COVID-CCMA-2022
Â Â  â”œâ”€â”€ Preprocessed_pickle
Â Â  â””â”€â”€ Raw_JSON
Â Â      â”œâ”€â”€ Discord
Â Â      â”œâ”€â”€ GotoMeeting
Â Â      â”œâ”€â”€ Meet
Â Â      â”œâ”€â”€ Messenger
Â Â      â”œâ”€â”€ Skype
Â Â      â”œâ”€â”€ Slack
Â Â      â”œâ”€â”€ Teams
Â Â      â”œâ”€â”€ Webex
Â Â      â””â”€â”€ Zoom
```

Notice the two subfolders:

* `Raw_JSON` gathers the nested JSON files for each experiment.

* `Preprocessed_pickle` is a pickle serialization of the 
data (undocumented by the authors).

#### Curation

Same as for [`mirage19` curation](datasets/install/#curation_2)


#### Splits

Again, similar to [`mirage19` splits](datasets/install/#splits_2).

The only difference is that we apply two
filtering on flow length (at least 10 packets and at least 1000 packets).


#### Install

To install the dataset run

```
tcbench datasets install --name mirage22
```

!!! note "Output"
	```
	â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
	â”‚download & unpackâ”‚
	â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
	Downloading... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.1 GB / 3.1 GB eta 0:00:00
	opening: /tmp/tmp3marsp7l/MIRAGE-COVID-CCMA-2022.zip
	opening: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/libtcdatasets/datasets/mirage22/raw/MIRAGE-COVID-CCMA-2022/Raw_JSON/Discord.zip
	opening: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/libtcdatasets/datasets/mirage22/raw/MIRAGE-COVID-CCMA-2022/Raw_JSON/GotoMeeting.zip
	opening: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/libtcdatasets/datasets/mirage22/raw/MIRAGE-COVID-CCMA-2022/Raw_JSON/Meet.zip
	opening: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/libtcdatasets/datasets/mirage22/raw/MIRAGE-COVID-CCMA-2022/Raw_JSON/Messenger.zip
	opening: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/libtcdatasets/datasets/mirage22/raw/MIRAGE-COVID-CCMA-2022/Raw_JSON/Skype.zip
	opening: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/libtcdatasets/datasets/mirage22/raw/MIRAGE-COVID-CCMA-2022/Raw_JSON/Slack.zip
	opening: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/libtcdatasets/datasets/mirage22/raw/MIRAGE-COVID-CCMA-2022/Raw_JSON/Teams.zip
	opening: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/libtcdatasets/datasets/mirage22/raw/MIRAGE-COVID-CCMA-2022/Raw_JSON/Webex.zip
	opening: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/libtcdatasets/datasets/mirage22/raw/MIRAGE-COVID-CCMA-2022/Raw_JSON/Zoom.zip

	â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
	â”‚preprocessâ”‚
	â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
	found 998 JSON files to load
	Converting JSONs... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 998/998 0:00:28
	merging files...
	saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/libtcdatasets/datasets/mirage22/preprocessed/mirage22.parquet

	â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
	â”‚filter & generate splitsâ”‚
	â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
	loading: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/mirage22/preprocessed/mirage22.parquet
	samples count : unfiltered
	â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
	â”ƒ app                              â”ƒ samples â”ƒ
	â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
	â”‚ background                       â”‚   18882 â”‚
	â”‚ com.microsoft.teams              â”‚    6541 â”‚
	â”‚ com.skype.raider                 â”‚    6203 â”‚
	â”‚ us.zoom.videomeetings            â”‚    5066 â”‚
	â”‚ com.cisco.webex.meetings         â”‚    4789 â”‚
	â”‚ com.discord                      â”‚    4337 â”‚
	â”‚ com.facebook.orca                â”‚    4321 â”‚
	â”‚ com.gotomeeting                  â”‚    3695 â”‚
	â”‚ com.Slack                        â”‚    2985 â”‚
	â”‚ com.google.android.apps.meetings â”‚    2252 â”‚
	â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
	â”‚ __total__                        â”‚   59071 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	stats : number packets per-flow (unfiltered)
	â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”“
	â”ƒ stat  â”ƒ     value â”ƒ
	â”¡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”©
	â”‚ count â”‚   59071.0 â”‚
	â”‚ mean  â”‚   3068.32 â”‚
	â”‚ std   â”‚  25416.43 â”‚
	â”‚ min   â”‚       1.0 â”‚
	â”‚ 25%   â”‚      20.0 â”‚
	â”‚ 50%   â”‚      27.0 â”‚
	â”‚ 75%   â”‚      42.0 â”‚
	â”‚ max   â”‚ 1665842.0 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

	filtering min_pkts=10...
	saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/mirage22/preprocessed/imc23/mirage22_filtered_minpkts10.parquet
	samples count : filtered (min_pkts=10)
	â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
	â”ƒ app                              â”ƒ samples â”ƒ
	â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
	â”‚ com.cisco.webex.meetings         â”‚    4437 â”‚
	â”‚ com.skype.raider                 â”‚    4117 â”‚
	â”‚ com.microsoft.teams              â”‚    3857 â”‚
	â”‚ us.zoom.videomeetings            â”‚    3587 â”‚
	â”‚ com.discord                      â”‚    3387 â”‚
	â”‚ com.facebook.orca                â”‚    2623 â”‚
	â”‚ com.gotomeeting                  â”‚    2557 â”‚
	â”‚ com.google.android.apps.meetings â”‚    1238 â”‚
	â”‚ com.Slack                        â”‚     970 â”‚
	â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
	â”‚ __total__                        â”‚   26773 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	stats : number packets per-flow (min_pkts=10)
	â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”“
	â”ƒ stat  â”ƒ     value â”ƒ
	â”¡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”©
	â”‚ count â”‚   26773.0 â”‚
	â”‚ mean  â”‚   6598.23 â”‚
	â”‚ std   â”‚  37290.08 â”‚
	â”‚ min   â”‚      11.0 â”‚
	â”‚ 25%   â”‚      15.0 â”‚
	â”‚ 50%   â”‚      21.0 â”‚
	â”‚ 75%   â”‚     186.0 â”‚
	â”‚ max   â”‚ 1665842.0 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/mirage22/preprocessed/imc23/mirage22_filtered_minpkts10_splits.parquet
	â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
	â”ƒ app                              â”ƒ train_samples â”ƒ val_samples â”ƒ test_samples â”ƒ all_samples â”ƒ
	â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
	â”‚ com.cisco.webex.meetings         â”‚          3594 â”‚         399 â”‚          444 â”‚        4437 â”‚
	â”‚ com.skype.raider                 â”‚          3334 â”‚         371 â”‚          412 â”‚        4117 â”‚
	â”‚ com.microsoft.teams              â”‚          3124 â”‚         347 â”‚          386 â”‚        3857 â”‚
	â”‚ us.zoom.videomeetings            â”‚          2905 â”‚         323 â”‚          359 â”‚        3587 â”‚
	â”‚ com.discord                      â”‚          2743 â”‚         305 â”‚          339 â”‚        3387 â”‚
	â”‚ com.facebook.orca                â”‚          2125 â”‚         236 â”‚          262 â”‚        2623 â”‚
	â”‚ com.gotomeeting                  â”‚          2072 â”‚         230 â”‚          255 â”‚        2557 â”‚
	â”‚ com.google.android.apps.meetings â”‚          1002 â”‚         112 â”‚          124 â”‚        1238 â”‚
	â”‚ com.Slack                        â”‚           786 â”‚          87 â”‚           97 â”‚         970 â”‚
	â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
	â”‚ __total__                        â”‚         21685 â”‚        2410 â”‚         2678 â”‚       26773 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

	filtering min_pkts=1000...
	saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/mirage22/preprocessed/imc23/mirage22_filtered_minpkts1000.parquet
	samples count : filtered (min_pkts=1000)
	â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
	â”ƒ app                              â”ƒ samples â”ƒ
	â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
	â”‚ com.discord                      â”‚    2220 â”‚
	â”‚ us.zoom.videomeetings            â”‚     425 â”‚
	â”‚ com.google.android.apps.meetings â”‚     379 â”‚
	â”‚ com.microsoft.teams              â”‚     321 â”‚
	â”‚ com.gotomeeting                  â”‚     297 â”‚
	â”‚ com.facebook.orca                â”‚     280 â”‚
	â”‚ com.cisco.webex.meetings         â”‚     259 â”‚
	â”‚ com.Slack                        â”‚     198 â”‚
	â”‚ com.skype.raider                 â”‚     190 â”‚
	â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
	â”‚ __total__                        â”‚    4569 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	stats : number packets per-flow (min_pkts=1000)
	â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”“
	â”ƒ stat  â”ƒ     value â”ƒ
	â”¡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”©
	â”‚ count â”‚    4569.0 â”‚
	â”‚ mean  â”‚  38321.32 â”‚
	â”‚ std   â”‚   83282.0 â”‚
	â”‚ min   â”‚    1001.0 â”‚
	â”‚ 25%   â”‚    2863.0 â”‚
	â”‚ 50%   â”‚    6303.0 â”‚
	â”‚ 75%   â”‚   35392.0 â”‚
	â”‚ max   â”‚ 1665842.0 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/mirage22/preprocessed/imc23/mirage22_filtered_minpkts1000_splits.parquet
	â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
	â”ƒ app                              â”ƒ train_samples â”ƒ val_samples â”ƒ test_samples â”ƒ all_samples â”ƒ
	â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
	â”‚ com.discord                      â”‚          1798 â”‚         200 â”‚          222 â”‚        2220 â”‚
	â”‚ us.zoom.videomeetings            â”‚           344 â”‚          39 â”‚           42 â”‚         425 â”‚
	â”‚ com.google.android.apps.meetings â”‚           307 â”‚          34 â”‚           38 â”‚         379 â”‚
	â”‚ com.microsoft.teams              â”‚           260 â”‚          29 â”‚           32 â”‚         321 â”‚
	â”‚ com.gotomeeting                  â”‚           240 â”‚          27 â”‚           30 â”‚         297 â”‚
	â”‚ com.facebook.orca                â”‚           227 â”‚          25 â”‚           28 â”‚         280 â”‚
	â”‚ com.cisco.webex.meetings         â”‚           210 â”‚          23 â”‚           26 â”‚         259 â”‚
	â”‚ com.Slack                        â”‚           160 â”‚          18 â”‚           20 â”‚         198 â”‚
	â”‚ com.skype.raider                 â”‚           154 â”‚          17 â”‚           19 â”‚         190 â”‚
	â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
	â”‚ __total__                        â”‚          3700 â”‚         412 â”‚          457 â”‚        4569 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	```

!!! note "Focusing on the reports..."

	Notice the following:

	* The unfiltered dataset shows a lot of small flows, but
	this bias reduces when applying the filtering.

## `utmobilenet21`

The dataset is a collection of per-packet CSV files 
related to 17 Android apps across 
4 different *partitions* each corresponding
to a different interaction with each app.

The dataset cannot be downloaded directly
(because it is stored into a Box cloud
storage) so you need to pre-download it
and save it into a folder.

For instance
```
downloads/
â””â”€â”€ UTMobileNet2021.zip
```

#### Original structure

Once unpacked, the datasets is organized as follows
```
downloads/
â””â”€â”€ csvs
 Â Â  â”œâ”€â”€ Action-Specific Wild Test Data
 Â Â  â”œâ”€â”€ Deterministic Automated Data
 Â Â  â”œâ”€â”€ Randomized Automated Data
 Â Â  â””â”€â”€ Wild Test Data
```

Each subfolders of `csvs/` corresponds to a different
partition (the folder name is informing you
about the semantic of the original measurement campaign).

Within each subfolder there is a collection of CSVs
generated running `tshark`, i.e., they are per-packet logs.

Differently from `mirage19` and `mirage22`, the only label available
is provided by CSV file names.

#### Curation

* Some of the original CSVs files have rows which
break the parsing via common utilities such as `pandas.read_csv()`.
Moreover, some columns have missing values, while others
have missing types between files (e.g., ports can be
either int of floats). So extra care is taken to properly
ingest the CSVs.

* We __Filter out packets__ which are not TCP or UDP.

* Then, packets are organized into flows using the traditional
network 5-tuple.

The final monolithic parquet files has the following columns

|Field|Description|
|:----|:----------|
|`row_id`|A unique flow id|
|`src_ip`|The source ip of the flow|
|`src_port`|The source port of the flow|
|`dst_ip`|The destination ip of the flow|
|`dst_port`|The destination port of the flow|
|`ip_proto`|The protocol of the flow (TCP or UDP)|
|`first`|Timestamp of the first packet|
|`last`|Timestamp of the last packet|
|`duration`|Duration of the flow|
|`packets`|Number of packets in the flow|
|`bytes`|Number of bytes in the flow|
|`partition`|From which folder the flow was originally stored|
|`location`|A label originally provided by the dataset (see the related paper for details)|
|`fname`|The original filename where the packets of the flow come from |
|`app`|The final label of the flow, encoded as pandas `category`|
|`pkts_size`|The numpy array for the packet size time series|
|`pkts_dir`|The numpy array for the packet diretion time series|
|`timetofirst`|The numpy array for the delta between the each packet timestamp the first packet of the flow|

#### Splits

Once preprocessed, the monolithic dataset is further processed to:

* Remove flows with < 10 samples
* Remove apps with < 100 samples

From the remaining traffic we define 5 train/val/test splits with the following logic

1. Shuffle the rows
2. Perform a 90/10 split where the 10-part is used for testing
3. From the 90-part, do a second 90/10 to define train and validation

The splits are NOT materialized, i.e., 
splits are a collection of row indexes
that needs to be applied on the filtered monolithic
parquet in order to obtain the data for modeling

The structure of the split table is

|Field|Description|
|:----|:----------|
|`train_indexes`|A numpy array with the `row_id` related to the train split|
|`val_indexes`| ... validation split|
|`test_indexes`| ... test split|
|`split_index`| The index of the split (0..4)|

#### Install

To install the dataset run
(assuming data was pre-downloaded under `/downloads`)

```
tcbench datasets install \
	--name utmobilenet21 \
	--input-folder downloads/
```

!!! info "Output"
	```
	â•­â”€â”€â”€â”€â”€â”€â•®
	â”‚unpackâ”‚
	â•°â”€â”€â”€â”€â”€â”€â•¯
	opening: downloads/UTMobileNet2021.zip

	â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
	â”‚preprocessâ”‚
	â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
	processing: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/libtcdatasets/datasets/utmobilenet21/raw/Action-Specific Wild Test Data
	found 43 files
	Converting CSVs... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 43/43 0:01:15
	stage1 completed
	stage2 completed
	stage3 completed
	stage4 completed
	saving: /tmp/processing-utmobilenet21/action-specific_wild_test_data.parquet

	processing: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/libtcdatasets/datasets/utmobilenet21/raw/Wild Test Data
	found 14 files
	Converting CSVs... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 14/14 0:03:12
	stage1 completed
	stage2 completed
	stage3 completed
	stage4 completed
	saving: /tmp/processing-utmobilenet21/wild_test_data.parquet

	processing: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/libtcdatasets/datasets/utmobilenet21/raw/Randomized Automated Data
	found 288 files
	Converting CSVs... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 288/288 0:01:35
	stage1 completed
	stage2 completed
	stage3 completed
	stage4 completed
	saving: /tmp/processing-utmobilenet21/randomized_automated_data.parquet

	processing: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/libtcdatasets/datasets/utmobilenet21/raw/Deterministic Automated Data
	found 3438 files
	Converting CSVs... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3438/3438 0:08:26
	stage1 completed
	stage2 completed
	stage3 completed
	stage4 completed
	saving: /tmp/processing-utmobilenet21/deterministic_automated_data.parquet
	merging all partitions
	saving: /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/libtcdatasets/datasets/utmobilenet21/preprocessed/utmobilenet21.parquet

	â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
	â”‚filter & generate splitsâ”‚
	â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
	loading: /opt/anaconda/anaconda3/envs/tcbench-johndoe/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/utmobilenet21/preprocessed/utmobilenet21.parquet
	samples count : unfiltered
	â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
	â”ƒ app          â”ƒ samples â”ƒ
	â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
	â”‚ youtube      â”‚    4716 â”‚
	â”‚ reddit       â”‚    3622 â”‚
	â”‚ google-maps  â”‚    3475 â”‚
	â”‚ netflix      â”‚    1804 â”‚
	â”‚ pinterest    â”‚    1702 â”‚
	â”‚ dropbox      â”‚    1609 â”‚
	â”‚ instagram    â”‚    1426 â”‚
	â”‚ gmail        â”‚     848 â”‚
	â”‚ google-drive â”‚     709 â”‚
	â”‚ messenger    â”‚     690 â”‚
	â”‚ hangout      â”‚     483 â”‚
	â”‚ facebook     â”‚     364 â”‚
	â”‚ twitter      â”‚     308 â”‚
	â”‚ hulu         â”‚     294 â”‚
	â”‚ spotify      â”‚     252 â”‚
	â”‚ pandora      â”‚      70 â”‚
	â”‚ skype        â”‚      57 â”‚
	â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
	â”‚ __total__    â”‚   22429 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	stats : number packets per-flow (unfiltered)
	â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”“
	â”ƒ stat  â”ƒ     value â”ƒ
	â”¡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”©
	â”‚ count â”‚   22429.0 â”‚
	â”‚ mean  â”‚    716.33 â”‚
	â”‚ std   â”‚  22271.93 â”‚
	â”‚ min   â”‚       1.0 â”‚
	â”‚ 25%   â”‚       2.0 â”‚
	â”‚ 50%   â”‚       2.0 â”‚
	â”‚ 75%   â”‚      15.0 â”‚
	â”‚ max   â”‚ 1973657.0 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

	saving: /opt/anaconda/anaconda3/envs/tcbench-johndoe/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/utmobilenet21/preprocessed/imc23/utmobilenet21_filtered_minpkts10.parquet
	samples count : filtered (min_pkts=10)
	â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
	â”ƒ app          â”ƒ samples â”ƒ
	â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
	â”‚ youtube      â”‚    2153 â”‚
	â”‚ google-maps  â”‚    1391 â”‚
	â”‚ reddit       â”‚     654 â”‚
	â”‚ netflix      â”‚     317 â”‚
	â”‚ pinterest    â”‚     312 â”‚
	â”‚ dropbox      â”‚     211 â”‚
	â”‚ instagram    â”‚     205 â”‚
	â”‚ hangout      â”‚     176 â”‚
	â”‚ hulu         â”‚     162 â”‚
	â”‚ google-drive â”‚     104 â”‚
	â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
	â”‚ __total__    â”‚    5685 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	stats : number packets per-flow (min_pkts=10)
	â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”“
	â”ƒ stat  â”ƒ     value â”ƒ
	â”¡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”©
	â”‚ count â”‚    5685.0 â”‚
	â”‚ mean  â”‚   2740.55 â”‚
	â”‚ std   â”‚  44152.43 â”‚
	â”‚ min   â”‚      11.0 â”‚
	â”‚ 25%   â”‚      25.0 â”‚
	â”‚ 50%   â”‚      44.0 â”‚
	â”‚ 75%   â”‚     156.0 â”‚
	â”‚ max   â”‚ 1973657.0 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	saving: /opt/anaconda/anaconda3/envs/tcbench-johndoe/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/utmobilenet21/preprocessed/imc23/utmobilenet21_filtered_minpkts10_splits.parquet
	â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
	â”ƒ app          â”ƒ train_samples â”ƒ val_samples â”ƒ test_samples â”ƒ all_samples â”ƒ
	â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
	â”‚ youtube      â”‚          1743 â”‚         194 â”‚          216 â”‚        2153 â”‚
	â”‚ google-maps  â”‚          1127 â”‚         125 â”‚          139 â”‚        1391 â”‚
	â”‚ reddit       â”‚           530 â”‚          59 â”‚           65 â”‚         654 â”‚
	â”‚ netflix      â”‚           256 â”‚          29 â”‚           32 â”‚         317 â”‚
	â”‚ pinterest    â”‚           253 â”‚          28 â”‚           31 â”‚         312 â”‚
	â”‚ dropbox      â”‚           171 â”‚          19 â”‚           21 â”‚         211 â”‚
	â”‚ instagram    â”‚           166 â”‚          18 â”‚           21 â”‚         205 â”‚
	â”‚ hangout      â”‚           142 â”‚          16 â”‚           18 â”‚         176 â”‚
	â”‚ hulu         â”‚           131 â”‚          15 â”‚           16 â”‚         162 â”‚
	â”‚ google-drive â”‚            85 â”‚           9 â”‚           10 â”‚         104 â”‚
	â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
	â”‚ __total__    â”‚          4604 â”‚         512 â”‚          569 â”‚        5685 â”‚
	â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	```

!!! note "Focusing on the reports..."

	Notice the following:

	* From the packet stats of the original (unfiltered)
	dataset we can see there are a lot of small flows.
	Those are removed when considering a minimum
	flow length of 10.

	* On top of this filtering we also remove
    apps with less than 100 flows, i.e., __only
    10 of the original 17 apps can be used for modeling__.
