{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2966526a-f8b0-4a8b-a0ba-8d0d6c40f7df",
   "metadata": {},
   "source": [
    "Let's import `tcbench` and map its alias `tcb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766c097f-cac4-42b8-812f-debc400c180d",
   "metadata": {},
   "source": [
    "The module automatically import a few functions and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505c5eee-92b1-41a6-afcc-8b09b3b2aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tcbench as tcb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce96900-5c77-49e2-9033-157e6517965f",
   "metadata": {},
   "source": [
    "## The `.get_datasets_root_folder()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c22dc74-f31c-4c7b-9ddf-6f1fd5144d69",
   "metadata": {},
   "source": [
    "You can first discover the <root> path where the datasets are\n",
    "installed using `.get_datasets_root_folder()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7bfbb24-44f8-4d96-a0a2-fe1e61a57db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_folder = tcb.get_datasets_root_folder()\n",
    "root_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f1fd3-f344-4cc0-98fa-024a95ec4e89",
   "metadata": {},
   "source": [
    "The function returns a [`pathlib` path](https://docs.python.org/3/library/pathlib.html?highlight=pathlib)\n",
    "so you can take advantage of it to navigate the subfolders structure.\n",
    "\n",
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d36299da-b3a0-4c24-a464-14d1b71190b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/utmobilenet21'),\n",
       " PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/mirage22'),\n",
       " PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/mirage19'),\n",
       " PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(root_folder.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f6bf2d-1a50-4e19-9089-834bfa17945d",
   "metadata": {},
   "source": [
    "As from the output, each dataset is mapped to a different folder \n",
    "named after the dataset itself. Meaning, again taking advantage of `pathlib`, \n",
    "you can compose path based on strings.\n",
    "\n",
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e9d5ab1-da4b-45a9-a16b-185a94f4d0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/raw'),\n",
       " PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list((root_folder / 'ucdavis-icdm19').iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea772b7-f115-4b7b-bb3f-d978cb2c2443",
   "metadata": {},
   "source": [
    "## The `.DATASETS` enum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb79f9-8df4-4f20-88f1-2294b812573f",
   "metadata": {},
   "source": [
    "A more polished way to reference datasets is via the `tcbench.DATASETS` attribute which corresponds to a [python enumeration](https://docs.python.org/3/library/enum.html?highlight=enum#enum.Enum) object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a869c1-9006-48f4-9811-42d26d80f0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(enum.EnumMeta,\n",
       " [<DATASETS.UCDAVISICDM19: 'ucdavis-icdm19'>,\n",
       "  <DATASETS.UTMOBILENET21: 'utmobilenet21'>,\n",
       "  <DATASETS.MIRAGE19: 'mirage19'>,\n",
       "  <DATASETS.MIRAGE22: 'mirage22'>])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tcb.DATASETS), list(tcb.DATASETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb36431-e3fc-4c05-a963-d7434e28d95d",
   "metadata": {},
   "source": [
    "## The `.get_dataset_folder()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6393a8-99be-495c-bbbb-27c3aa0c0424",
   "metadata": {},
   "source": [
    "For instance, you can bypass the composition of a dataset folder path\n",
    "and call directly `.get_dataset_folder()` to find the specific \n",
    "dataset folder you look for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f55ee78e-de35-4fdf-8b65-1f64cbe6b179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_folder = tcb.get_dataset_folder(tcb.DATASETS.UCDAVISICDM19)\n",
    "dataset_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac5d66-f68a-45a7-9172-0194fc794b43",
   "metadata": {},
   "source": [
    "## Listing files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f4eae-31d8-494b-9669-c783f28e915a",
   "metadata": {},
   "source": [
    "Via `pathlib` you can easily discover all parquet files composing a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd0d055-bcc8-4175-bf15-5aa548cc853c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/ucdavis-icdm19.parquet'),\n",
       " PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/imc23/train_split_3.parquet'),\n",
       " PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/imc23/train_split_4.parquet'),\n",
       " PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/imc23/test_split_human.parquet'),\n",
       " PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/imc23/train_split_0.parquet'),\n",
       " PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/imc23/test_split_script.parquet'),\n",
       " PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/imc23/train_split_2.parquet'),\n",
       " PosixPath('/opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets/ucdavis-icdm19/preprocessed/imc23/train_split_1.parquet')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset_folder.rglob('*.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a64d0a-c3f0-4861-bad5-1b147d9a7022",
   "metadata": {},
   "source": [
    "But you can also programmatically call the the `datasets lsparquet` subcommand of the CLI using `get_rich_tree_parquet_files()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ba52872-9289-4794-b7fb-b0ad0dbb7468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Datasets\n",
       "‚îî‚îÄ‚îÄ ucdavis-icdm19\n",
       "    ‚îî‚îÄ‚îÄ üìÅ preprocessed/\n",
       "        ‚îú‚îÄ‚îÄ ucdavis-icdm19.parquet\n",
       "        ‚îî‚îÄ‚îÄ üìÅ imc23/\n",
       "            ‚îú‚îÄ‚îÄ test_split_human.parquet\n",
       "            ‚îú‚îÄ‚îÄ test_split_script.parquet\n",
       "            ‚îú‚îÄ‚îÄ train_split_0.parquet\n",
       "            ‚îú‚îÄ‚îÄ train_split_1.parquet\n",
       "            ‚îú‚îÄ‚îÄ train_split_2.parquet\n",
       "            ‚îú‚îÄ‚îÄ train_split_3.parquet\n",
       "            ‚îî‚îÄ‚îÄ train_split_4.parquet\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Datasets\n",
       "‚îî‚îÄ‚îÄ ucdavis-icdm19\n",
       "    ‚îî‚îÄ‚îÄ üìÅ preprocessed/\n",
       "        ‚îú‚îÄ‚îÄ ucdavis-icdm19.parquet\n",
       "        ‚îî‚îÄ‚îÄ üìÅ imc23/\n",
       "            ‚îú‚îÄ‚îÄ test_split_human.parquet\n",
       "            ‚îú‚îÄ‚îÄ test_split_script.parquet\n",
       "            ‚îú‚îÄ‚îÄ train_split_0.parquet\n",
       "            ‚îú‚îÄ‚îÄ train_split_1.parquet\n",
       "            ‚îú‚îÄ‚îÄ train_split_2.parquet\n",
       "            ‚îú‚îÄ‚îÄ train_split_3.parquet\n",
       "            ‚îî‚îÄ‚îÄ train_split_4.parquet\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tcbench.libtcdatasets.datasets_utils import get_rich_tree_parquet_files\n",
    "get_rich_tree_parquet_files(tcb.DATASETS.UCDAVISICDM19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b6bfe-92ff-4f47-a689-9e28b832761d",
   "metadata": {},
   "source": [
    "## The `.load_parquet()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c58528-62e9-4336-bef4-bc3185ddf29b",
   "metadata": {},
   "source": [
    "Finally, the generic `.load_parquet()` can be used to load one of the parquet files.\n",
    "\n",
    "For instance, the following load the unfiltered monolithic file of the `ucdavis-icdm19` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdae8f94-1bfb-4c27-a38b-c22cd181d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tcb.load_parquet(tcb.DATASETS.UCDAVISICDM19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dadb3a7-4489-49a3-98f8-e9c5a8e8cb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>app</th>\n",
       "      <th>flow_id</th>\n",
       "      <th>partition</th>\n",
       "      <th>num_pkts</th>\n",
       "      <th>duration</th>\n",
       "      <th>bytes</th>\n",
       "      <th>unixtime</th>\n",
       "      <th>timetofirst</th>\n",
       "      <th>pkts_size</th>\n",
       "      <th>pkts_dir</th>\n",
       "      <th>pkts_iat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>google-doc</td>\n",
       "      <td>GoogleDoc-100</td>\n",
       "      <td>pretraining</td>\n",
       "      <td>2925</td>\n",
       "      <td>116.348</td>\n",
       "      <td>816029</td>\n",
       "      <td>[1527993495.652867, 1527993495.685678, 1527993...</td>\n",
       "      <td>[0.0, 0.0328109, 0.261392, 0.262656, 0.263943,...</td>\n",
       "      <td>[354, 87, 323, 1412, 1412, 107, 1412, 180, 141...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0328109, 0.2285811, 0.0012639999999999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>google-doc</td>\n",
       "      <td>GoogleDoc-1000</td>\n",
       "      <td>pretraining</td>\n",
       "      <td>2813</td>\n",
       "      <td>116.592</td>\n",
       "      <td>794628</td>\n",
       "      <td>[1527987720.40456, 1527987720.422811, 15279877...</td>\n",
       "      <td>[0.0, 0.0182509, 0.645106, 0.646344, 0.647689,...</td>\n",
       "      <td>[295, 87, 301, 1412, 1412, 1412, 180, 113, 141...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0182509, 0.6268551, 0.0012380000000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id         app         flow_id    partition  num_pkts  duration  \\\n",
       "0       0  google-doc   GoogleDoc-100  pretraining      2925   116.348   \n",
       "1       1  google-doc  GoogleDoc-1000  pretraining      2813   116.592   \n",
       "\n",
       "    bytes                                           unixtime  \\\n",
       "0  816029  [1527993495.652867, 1527993495.685678, 1527993...   \n",
       "1  794628  [1527987720.40456, 1527987720.422811, 15279877...   \n",
       "\n",
       "                                         timetofirst  \\\n",
       "0  [0.0, 0.0328109, 0.261392, 0.262656, 0.263943,...   \n",
       "1  [0.0, 0.0182509, 0.645106, 0.646344, 0.647689,...   \n",
       "\n",
       "                                           pkts_size  \\\n",
       "0  [354, 87, 323, 1412, 1412, 107, 1412, 180, 141...   \n",
       "1  [295, 87, 301, 1412, 1412, 1412, 180, 113, 141...   \n",
       "\n",
       "                                            pkts_dir  \\\n",
       "0  [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, ...   \n",
       "1  [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "\n",
       "                                            pkts_iat  \n",
       "0  [0.0, 0.0328109, 0.2285811, 0.0012639999999999...  \n",
       "1  [0.0, 0.0182509, 0.6268551, 0.0012380000000000...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86e1f0c0-ae31-401d-9f9b-437211d15133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "partition                    app          \n",
       "pretraining                  google-doc       1221\n",
       "                             google-drive     1634\n",
       "                             google-music      592\n",
       "                             google-search    1915\n",
       "                             youtube          1077\n",
       "retraining-human-triggered   google-doc         15\n",
       "                             google-drive       18\n",
       "                             google-music       15\n",
       "                             google-search      15\n",
       "                             youtube            20\n",
       "retraining-script-triggered  google-doc         30\n",
       "                             google-drive       30\n",
       "                             google-music       30\n",
       "                             google-search      30\n",
       "                             youtube            30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['partition', 'app'])['app'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb2ad21-8349-41d7-beaf-2e952c94ff9b",
   "metadata": {},
   "source": [
    "Beside the dataset name, the function only has 2 other parameters, but\n",
    "their semantic and values are \"mingled\" with the curation process adopted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94f9096a-7356-4a33-ba36-ce63bd807166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mtcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdataset_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | DATASETS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_pkts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msplit\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'pd.DataFrame'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Load and returns a dataset parquet file\n",
       "\n",
       "Arguments:\n",
       "    dataset_name: The name of the dataset\n",
       "    min_pkts: the filtering rule applied when curating the datasets.\n",
       "        If -1, load the unfiltered dataset\n",
       "    split: if min_pkts!=-1, is used to request the loading of \n",
       "        the split file. For DATASETS.UCDAVISICDM19 \n",
       "        values can be \"human\", \"script\" or a number \n",
       "        between 0 and 4.\n",
       "        For all other dataset split can be anything \n",
       "        which is not None (e.g., True)\n",
       "\n",
       "Returns:\n",
       "    A pandas dataframe\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/anaconda/anaconda3/envs/tcbench/lib/python3.10/site-packages/tcbench/libtcdatasets/datasets_utils.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tcb.load_parquet?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed5c8dd-5a67-4640-a9e6-1530c8443eb6",
   "metadata": {},
   "source": [
    "## How `.load_parquet()` maps to parquet files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd18424-e0f6-4c89-bc11-3d692d32778d",
   "metadata": {},
   "source": [
    "The logic to follow to load specific files can be confusing. The table below report a global view across datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad130391-0268-45df-b67e-ab04e3eefb70",
   "metadata": {},
   "source": [
    "| Dataset | min_pkts=-1 | min_pkts=10 | min_pkts=1000 | split=True | split=0..4 | split=human | split=script |\n",
    "|:-------:|:-------------:|:-------------:|:---------------:|:------------:|:------------:|:-------------:|:--------------:|\n",
    "|`ucdavis-icdm19`| yes | - | - | - | yes (train+val) | yes (test)| yes (test)|\n",
    "|`mirage19`| yes | yes| - | yes (train/val/test) | - | - | - |\n",
    "|`mirage22`| yes | yes |yes|yes (train/val/test) | - | - | - | \n",
    "|`utmobilenet21`| yes | yes |-|yes (train/val/test) | - | - | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce9372b-9bb0-4cb7-ad32-4581b88dd00b",
   "metadata": {},
   "source": [
    "* `min_pkts=-1` is set by default and corresponds to loading the unfiltered parquet files, i.e., the files stored immediately under `/preprocessed`. All other files are stored under the `imc23` subfolders\n",
    "\n",
    "* For `ucdavis-icdm19`, the parameter `min_pkts` is not used. The loading of training(+validation) and test data is controlled by `split`\n",
    "\n",
    "* For all other datasets, `min_pkts` specifies which filtered version of the data to use, while `split=True` load the split indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297397b9-23a9-4216-a693-a5a0e5f772c4",
   "metadata": {},
   "source": [
    "## Loading `ucdavis-icdm19`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c32721-771c-423e-ba60-a4679f6b91af",
   "metadata": {},
   "source": [
    "For instance, to load the `human` test split of `ucdavid-icdm19` you can run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dd06d61-c1f0-46dc-8d7f-04e3a18c7318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "app\n",
       "youtube          20\n",
       "google-drive     18\n",
       "google-doc       15\n",
       "google-music     15\n",
       "google-search    15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tcb.load_parquet(tcb.DATASETS.UCDAVISICDM19, split='human')\n",
    "df['app'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a4b708-5300-49e0-894d-dcbb7ba586ee",
   "metadata": {},
   "source": [
    "And the logic is very similar for the `script` partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f39a7be-9593-4802-b32e-a637aa6170c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "app\n",
       "google-doc       30\n",
       "google-drive     30\n",
       "google-music     30\n",
       "google-search    30\n",
       "youtube          30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tcb.load_parquet(tcb.DATASETS.UCDAVISICDM19, split='script')\n",
    "df['app'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9abb8c8-f1be-43eb-b94c-343ef4506c77",
   "metadata": {},
   "source": [
    "However to load a specific train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfb4231a-fb41-4c02-952e-c0eaba335e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "app\n",
       "google-doc       100\n",
       "google-drive     100\n",
       "google-music     100\n",
       "google-search    100\n",
       "youtube          100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tcb.load_parquet(tcb.DATASETS.UCDAVISICDM19, split='0')\n",
    "df['app'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b995660e-e7e7-46ed-a54a-657b67f2c389",
   "metadata": {},
   "source": [
    "## Loading other datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5711df8d-90b5-4f3e-b580-084c919f5ed3",
   "metadata": {},
   "source": [
    "By default, without any parameter beside the dataset name, the function loads the unfiltered version of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f61ab19-a188-4124-8b38-e292c688c4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122007, 135)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tcb.load_parquet(tcb.DATASETS.MIRAGE19)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58e2659-1ccb-45f0-a153-6e7775f7d1b1",
   "metadata": {},
   "source": [
    "Recall the structure of the `mirage19` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "461ca902-ded8-4070-896e-81c9ef674fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Datasets\n",
       "‚îî‚îÄ‚îÄ mirage19\n",
       "    ‚îî‚îÄ‚îÄ üìÅ preprocessed/\n",
       "        ‚îú‚îÄ‚îÄ mirage19.parquet\n",
       "        ‚îî‚îÄ‚îÄ üìÅ imc23/\n",
       "            ‚îú‚îÄ‚îÄ mirage19_filtered_minpkts10.parquet\n",
       "            ‚îî‚îÄ‚îÄ mirage19_filtered_minpkts10_splits.parquet\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Datasets\n",
       "‚îî‚îÄ‚îÄ mirage19\n",
       "    ‚îî‚îÄ‚îÄ üìÅ preprocessed/\n",
       "        ‚îú‚îÄ‚îÄ mirage19.parquet\n",
       "        ‚îî‚îÄ‚îÄ üìÅ imc23/\n",
       "            ‚îú‚îÄ‚îÄ mirage19_filtered_minpkts10.parquet\n",
       "            ‚îî‚îÄ‚îÄ mirage19_filtered_minpkts10_splits.parquet\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rich_tree_parquet_files(tcb.DATASETS.MIRAGE19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d31391-082a-4d5f-a7b6-49c1cb594974",
   "metadata": {},
   "source": [
    "So there is only one filtering with `min_pkts=10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f5d795c-2b79-428b-b827-454c24f60a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64172, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tcb.load_parquet(tcb.DATASETS.MIRAGE19, min_pkts=10)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72227e97-eebc-4e21-b88d-fd3ca9cf84ed",
   "metadata": {},
   "source": [
    "Based on the dataframe shape, we can see that (indeed) we loaded a reduced version of the unfiltered dataset.\n",
    "\n",
    "While for `ucdavis-icdm19` the \"split\" files represent 100 samples selected for training (because there are two ad-hoc test split), for all other dataset the \"split\" files contains indexes indicating the rows to use for train/val/test.\n",
    "\n",
    "Thus, issuing `split=True` is enough to indicate the need to load the split table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a253cfee-020a-4741-863c-58323f079423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_indexes</th>\n",
       "      <th>val_indexes</th>\n",
       "      <th>test_indexes</th>\n",
       "      <th>split_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[18965, 24694, 59797, 35708, 42030, 356, 39052...</td>\n",
       "      <td>[36752, 7114, 48500, 39083, 44382, 58758, 2001...</td>\n",
       "      <td>[20363, 36256, 24604, 11752, 40529, 50086, 470...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[8741, 55715, 47053, 37161, 59608, 6777, 47281...</td>\n",
       "      <td>[41506, 56625, 18344, 23114, 10634, 44785, 130...</td>\n",
       "      <td>[21524, 19560, 41837, 57207, 35174, 38440, 563...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[58596, 59589, 26514, 56766, 51386, 20802, 453...</td>\n",
       "      <td>[11552, 34447, 16180, 21248, 28195, 16763, 387...</td>\n",
       "      <td>[43026, 28228, 29243, 27753, 50389, 48093, 85,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[22303, 11403, 53901, 919, 54389, 22144, 51538...</td>\n",
       "      <td>[26990, 50118, 45109, 29126, 16420, 10965, 257...</td>\n",
       "      <td>[10721, 35420, 47187, 51800, 30736, 44707, 134...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[21918, 7887, 5426, 22788, 40262, 34857, 58966...</td>\n",
       "      <td>[30232, 23269, 16058, 30390, 60505, 26499, 258...</td>\n",
       "      <td>[7366, 48552, 27092, 40144, 19834, 15065, 5229...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       train_indexes  \\\n",
       "0  [18965, 24694, 59797, 35708, 42030, 356, 39052...   \n",
       "1  [8741, 55715, 47053, 37161, 59608, 6777, 47281...   \n",
       "2  [58596, 59589, 26514, 56766, 51386, 20802, 453...   \n",
       "3  [22303, 11403, 53901, 919, 54389, 22144, 51538...   \n",
       "4  [21918, 7887, 5426, 22788, 40262, 34857, 58966...   \n",
       "\n",
       "                                         val_indexes  \\\n",
       "0  [36752, 7114, 48500, 39083, 44382, 58758, 2001...   \n",
       "1  [41506, 56625, 18344, 23114, 10634, 44785, 130...   \n",
       "2  [11552, 34447, 16180, 21248, 28195, 16763, 387...   \n",
       "3  [26990, 50118, 45109, 29126, 16420, 10965, 257...   \n",
       "4  [30232, 23269, 16058, 30390, 60505, 26499, 258...   \n",
       "\n",
       "                                        test_indexes  split_index  \n",
       "0  [20363, 36256, 24604, 11752, 40529, 50086, 470...            0  \n",
       "1  [21524, 19560, 41837, 57207, 35174, 38440, 563...            1  \n",
       "2  [43026, 28228, 29243, 27753, 50389, 48093, 85,...            2  \n",
       "3  [10721, 35420, 47187, 51800, 30736, 44707, 134...            3  \n",
       "4  [7366, 48552, 27092, 40144, 19834, 15065, 5229...            4  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split = tcb.load_parquet(tcb.DATASETS.MIRAGE19, min_pkts=10, split=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
